{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "plt.rcParams['image.cmap'] = 'gist_earth'\n",
    "np.random.seed(98765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation \n",
    "# Random Crop\n",
    "# Random Flip\n",
    "import os\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, TenCrop, Lambda\n",
    "import torchvision.transforms as vis_tf\n",
    "from glob import glob\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append('/Users/trimchala/BreastPathQ/breastpathq/tf_unet/')\n",
    "import tf_unet\n",
    "from tf_unet.image_util import BaseDataProvider\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "dataset_path = '/Users/trimchala/BreastPathQ/breastpathq/datasets/MoNuSegTraining'\n",
    "image_path = os.path.join(dataset_path, 'TissueImages')\n",
    "mask_path = os.path.join(dataset_path, 'LabeledNucImages')\n",
    "\n",
    "\n",
    "class MonuSegDataProvider(BaseDataProvider):\n",
    "    def __init__(\n",
    "        self, \n",
    "        image_path, \n",
    "        mask_path, \n",
    "        transforms=None, shuffle_data=True, \n",
    "        a_min=None, a_max=None, \n",
    "    ):\n",
    "        super(MonuSegDataProvider, self).__init__(a_min, a_max)\n",
    "        # stuff\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.file_idx = -1\n",
    "        self.transforms = transforms\n",
    "        self.image_list = glob(os.path.join(self.image_path, \"*.tif\"))\n",
    "        self.mask_list = glob(os.path.join(self.mask_path, \"*.png\"))\n",
    "        self.shuffle_data = shuffle_data\n",
    "        \n",
    "#         if self.shuffle_data:\n",
    "#             np.random.shuffle(self.data_files)\n",
    "        \n",
    "        assert len(self.image_list) > 0, \"No training files\"\n",
    "        print(\"Number of files used: %s\" % len(self.image_list))\n",
    "        \n",
    "        test_img = cv2.imread(image_list[0])\n",
    "        self.channels = 1 if len(test_img.shape) == 2 else test_img.shape[-1]\n",
    "        \n",
    "    def _load_file(self, path, dtype=np.float32):\n",
    "        return np.array(PIL.Image.open(path), dtype)\n",
    "\n",
    "    \n",
    "    def _cylce_file(self):\n",
    "        self.file_idx += 1\n",
    "        if self.file_idx >= len(self.image_list):\n",
    "            self.file_idx = 0 \n",
    "#             if self.shuffle_data:\n",
    "#                 np.random.shuffle(self.image_list)\n",
    "\n",
    "\n",
    "    def _next_data(self):\n",
    "        self._cylce_file()\n",
    "        image_file = self.image_list[self.file_idx]\n",
    "        mask_file = self.mask_list[self.file_idx]\n",
    "        \n",
    "        img = cv2.imread(image_file)        \n",
    "        mask_gray = np.array(\n",
    "            PIL.Image.fromarray(cv2.imread(mask_list[0])).convert('L')\n",
    "        )\n",
    "#         mask0 = (mask_gray <= mask_gray.min()).astype(int)\n",
    "#         mask1 = (mask_gray > mask_gray.min()).astype(int)\n",
    "#         mask = np.dstack([mask0, mask1])\n",
    "        mask = (mask_gray <= mask_gray.min()).astype(int)\n",
    "                        \n",
    "#         if self.transforms is not None:\n",
    "#             img = self.transforms(img)\n",
    "#             mask = self.transforms(mask)\n",
    "#         else: \n",
    "#             pil2tensor = vis_tf.Compose([vis_tf.ToTensor()])\n",
    "#             img = pil2tensor(img)\n",
    "#             mask = pil2tensor(mask)\n",
    "    \n",
    "        return img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-23 17:36:43,761 Layers 3, features 16, filter size 3x3, pool size: 2x2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files used: 30\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/trimchala/BreastPathQ/breastpathq/tf_unet/')\n",
    "sys.path.append('/Users/trimchala/BreastPathQ/breastpathq/tf_unet/tf_unet/')\n",
    "sys.path.append('/Users/trimchala/BreastPathQ/breastpathq/tf_unet/scripts/')\n",
    "os.chdir('/Users/trimchala/BreastPathQ/breastpathq/tf_unet/')\n",
    "from tf_unet import image_gen\n",
    "from tf_unet import unet\n",
    "from tf_unet import util\n",
    "\n",
    "monuseg_generator = MonuSegDataProvider(image_path, mask_path)\n",
    "\n",
    "unet32 = unet.Unet(\n",
    "    channels=monuseg_generator.channels, \n",
    "    n_class=monuseg_generator.n_class, \n",
    "    layers=3, \n",
    "    features_root=16\n",
    ")\n",
    "\n",
    "trainer = unet.Trainer(unet32, optimizer=\"momentum\", opt_kwargs=dict(momentum=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1000, 3), (1000, 1000))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, mask = monuseg_generator._next_data()\n",
    "image.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-23 17:36:50,104 Removing '/Users/trimchala/BreastPathQ/breastpathq/tf_unet/prediction'\n",
      "2018-11-23 17:36:50,106 Removing '/Users/trimchala/BreastPathQ/breastpathq/tf_unet/tf_unet_monuseg_trained'\n",
      "2018-11-23 17:36:50,108 Allocating '/Users/trimchala/BreastPathQ/breastpathq/tf_unet/prediction'\n",
      "2018-11-23 17:36:50,109 Allocating '/Users/trimchala/BreastPathQ/breastpathq/tf_unet/tf_unet_monuseg_trained'\n",
      "2018-11-23 17:37:26,533 Verification error= 0.0%, loss= -0.8830\n",
      "2018-11-23 17:37:29,105 Start optimization\n",
      "2018-11-23 17:37:55,206 Iter 0, Minibatch Loss= -1.1550, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:39:01,935 Iter 5, Minibatch Loss= -2.3860, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:39:58,143 Iter 10, Minibatch Loss= -2.3684, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:40:48,996 Iter 15, Minibatch Loss= -2.4253, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:42:05,376 Iter 20, Minibatch Loss= -2.4367, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:43:09,739 Iter 25, Minibatch Loss= -2.4359, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:44:11,429 Iter 30, Minibatch Loss= -2.4544, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:44:27,047 Epoch 0, Average loss: -2.4253, learning rate: 0.2000\n",
      "2018-11-23 17:44:44,859 Verification error= 0.0%, loss= -2.6287\n",
      "2018-11-23 17:45:40,358 Iter 35, Minibatch Loss= -2.4546, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:46:53,659 Iter 40, Minibatch Loss= -2.4714, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:47:56,858 Iter 45, Minibatch Loss= -2.4830, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:49:02,348 Iter 50, Minibatch Loss= -2.4798, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:50:17,557 Iter 55, Minibatch Loss= -2.4960, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:51:18,029 Iter 60, Minibatch Loss= -2.4956, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:51:53,376 Epoch 1, Average loss: -2.5830, learning rate: 0.1900\n",
      "2018-11-23 17:52:10,006 Verification error= 0.0%, loss= -2.5121\n",
      "2018-11-23 17:52:35,796 Iter 65, Minibatch Loss= -2.4889, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:53:32,499 Iter 70, Minibatch Loss= -2.5298, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:54:29,343 Iter 75, Minibatch Loss= -2.5124, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:55:28,605 Iter 80, Minibatch Loss= -2.5122, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:56:28,834 Iter 85, Minibatch Loss= -2.5332, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:57:35,719 Iter 90, Minibatch Loss= -2.5222, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:58:34,820 Iter 95, Minibatch Loss= -2.5215, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 17:58:34,822 Epoch 2, Average loss: -2.5926, learning rate: 0.1805\n",
      "2018-11-23 17:58:53,492 Verification error= 0.0%, loss= -2.5492\n",
      "2018-11-23 18:00:02,844 Iter 100, Minibatch Loss= -2.5617, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:01:13,323 Iter 105, Minibatch Loss= -2.5333, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:02:37,035 Iter 110, Minibatch Loss= -2.5372, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:03:36,438 Iter 115, Minibatch Loss= -2.5503, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:04:35,645 Iter 120, Minibatch Loss= -2.5414, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:05:36,418 Iter 125, Minibatch Loss= -2.5425, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:05:58,861 Epoch 3, Average loss: -2.6021, learning rate: 0.1715\n",
      "2018-11-23 18:06:21,455 Verification error= 0.0%, loss= -2.5932\n",
      "2018-11-23 18:06:57,098 Iter 130, Minibatch Loss= -2.5797, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:07:58,372 Iter 135, Minibatch Loss= -2.5510, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:09:02,956 Iter 140, Minibatch Loss= -2.5540, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:10:10,783 Iter 145, Minibatch Loss= -2.5646, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:11:14,804 Iter 150, Minibatch Loss= -2.5570, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:12:53,369 Iter 155, Minibatch Loss= -2.5574, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:13:44,419 Epoch 4, Average loss: -2.6149, learning rate: 0.1629\n",
      "2018-11-23 18:14:01,196 Verification error= 0.0%, loss= -2.6220\n",
      "2018-11-23 18:14:14,983 Iter 160, Minibatch Loss= -2.5900, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:15:17,250 Iter 165, Minibatch Loss= -2.5641, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2018-11-23 18:16:24,366 Iter 170, Minibatch Loss= -2.5668, Training Accuracy= 1.0000, Minibatch error= 0.0%\n"
     ]
    }
   ],
   "source": [
    "path = trainer.train(\n",
    "    monuseg_generator, \n",
    "    \"./tf_unet_monuseg_trained\", \n",
    "    training_iters=32, epochs=10,\n",
    "    display_step=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stepping through unet.Trainier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
